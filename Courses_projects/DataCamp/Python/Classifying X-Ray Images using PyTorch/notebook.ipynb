{"cells":[{"source":"Pneumonia is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is essential for effective treatment. Manually reviewing chest X-rays is a critical step in this process, and AI can provide valuable support by helping to expedite the assessment. In your role as a consultant data scientist, you will test the ability of a deep learning model to distinguish pneumonia cases from normal images of lungs in chest X-rays.\n\nBy fine-tuning a pre-trained convolutional neural network, specifically the ResNet-18 model, your task is to classify X-ray images into two categories: normal lungs and those affected by pneumonia. You can leverage its already trained weights and get an accurate classifier trained faster and with fewer resources.\n\n## The Data\n\n<img src=\"x-rays_sample.png\" align=\"center\"/>\n&nbsp\n\nYou have a dataset of chest X-rays that have been preprocessed for use with a ResNet-18 model. You can see a sample of 5 images from each category above. Upon unzipping the `chestxrays.zip` file (code provided below), you will find your dataset inside the `data/chestxrays` folder divided into `test` and `train` folders. \n\nThere are 150 training images and 50 testing images for each category, NORMAL and PNEUMONIA (300 and 100 in total). For your convenience, this data has already been loaded into a `train_loader` and a `test_loader` using the `DataLoader` class from the PyTorch library. ","metadata":{},"id":"85dc467a-5830-44c0-ab74-435be0e5593c","cell_type":"markdown"},{"source":"# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics","metadata":{"executionCancelledAt":null,"executionTime":3028,"lastExecutedAt":1732990475587,"lastExecutedByKernel":"433e612a-2aca-4743-b3df-878fc684ba63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"0f522b79-2a5a-4472-adb9-0d924870bfa1","cell_type":"code","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\nRequirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.5.2)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.9.0)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1732990475640,"lastExecutedByKernel":"433e612a-2aca-4743-b3df-878fc684ba63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)"},"id":"cb1bedee-bcd5-4c80-a5ed-93df89af0295","cell_type":"code","execution_count":10,"outputs":[]},{"source":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1732990475692,"lastExecutedByKernel":"433e612a-2aca-4743-b3df-878fc684ba63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')"},"id":"dd91680d-cb63-4876-9a51-4ee6bb250c7d","cell_type":"code","execution_count":11,"outputs":[]},{"source":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1732990475744,"lastExecutedByKernel":"433e612a-2aca-4743-b3df-878fc684ba63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"},"id":"0cc5591a-8dc1-4d7f-88d2-3b1a59fb2a5f","cell_type":"code","execution_count":12,"outputs":[]},{"source":"# Load pre-trained ResNet-18 model\nresnet18 = models.resnet18(pretrained=True)\n\n# Freeze all layers except the final fully connected layer\nfor param in resnet18.parameters():\n    param.requires_grad = False\n\n# Modify the final fully connected layer\nnum_ftrs = resnet18.fc.in_features\nresnet18.fc = nn.Linear(num_ftrs, 1)  # Binary classification (NORMAL vs PNEUMONIA)\n\n# Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(resnet18.fc.parameters(), lr=0.001)\n","metadata":{"executionCancelledAt":null,"executionTime":192,"lastExecutedAt":1732990475936,"lastExecutedByKernel":"433e612a-2aca-4743-b3df-878fc684ba63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load pre-trained ResNet-18 model\nresnet18 = models.resnet18(pretrained=True)\n\n# Freeze all layers except the final fully connected layer\nfor param in resnet18.parameters():\n    param.requires_grad = False\n\n# Modify the final fully connected layer\nnum_ftrs = resnet18.fc.in_features\nresnet18.fc = nn.Linear(num_ftrs, 1)  # Binary classification (NORMAL vs PNEUMONIA)\n\n# Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(resnet18.fc.parameters(), lr=0.001)\n","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"id":"c99cf95b-83f3-49e4-9777-4e70736452d8","cell_type":"code","execution_count":13,"outputs":[]},{"source":"# Set model to training mode\nresnet18.train()\n\n# Fine-tuning loop\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n    \n    for inputs, labels in train_loader:\n        # Convert labels to float for binary classification\n        labels = labels.float().unsqueeze(1)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = resnet18(inputs)\n        \n        # Compute loss\n        loss = criterion(outputs, labels)\n        \n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Print epoch loss\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')","metadata":{"executionCancelledAt":null,"executionTime":67878,"lastExecutedAt":1732990543816,"lastExecutedByKernel":"433e612a-2aca-4743-b3df-878fc684ba63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Set model to training mode\nresnet18.train()\n\n# Fine-tuning loop\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n    \n    for inputs, labels in train_loader:\n        # Convert labels to float for binary classification\n        labels = labels.float().unsqueeze(1)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = resnet18(inputs)\n        \n        # Compute loss\n        loss = criterion(outputs, labels)\n        \n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Print epoch loss\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"783b41f9-98b3-451c-981c-bb1714f6feb1","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch [1/3], Loss: 0.6941\nEpoch [2/3], Loss: 0.6431\nEpoch [3/3], Loss: 0.6169\n"}],"execution_count":14},{"source":"### Below is the provided model evaluation code. Run the below cell to help you evaluate the accuracy and F1-score of your fine-tuned model.","metadata":{},"id":"70761893-e66f-40fe-8862-dac9b18a13ab","cell_type":"markdown"},{"source":"#-------------------\n# Evaluate the model\n#-------------------\n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    # Convert lists back to tensors\n    all_preds = torch.tensor(all_preds)\n    all_labels = torch.tensor(all_labels)\n\n    # Calculate accuracy and F1 score\n    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n    test_f1_score = f1_metric(all_preds, all_labels).item()","metadata":{"executionCancelledAt":null,"executionTime":7359,"lastExecutedAt":1732990551177,"lastExecutedByKernel":"433e612a-2aca-4743-b3df-878fc684ba63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#-------------------\n# Evaluate the model\n#-------------------\n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    # Convert lists back to tensors\n    all_preds = torch.tensor(all_preds)\n    all_labels = torch.tensor(all_labels)\n\n    # Calculate accuracy and F1 score\n    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n    test_f1_score = f1_metric(all_preds, all_labels).item()"},"id":"7e0e1ad6-2f78-4a14-943b-8cc7c9dfe960","cell_type":"code","execution_count":15,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}