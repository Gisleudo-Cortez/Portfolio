{"cells":[{"source":"![Traffic](traffic.png)\n\nTraffic data fluctuates constantly or is affected by time. Predicting it can be challenging, but this task will help sharpen your time-series skills. With deep learning, you can use abstract patterns in data that can help boost predictability.\n\nYour task is to build a system that can be applied to help you predict traffic volume or the number of vehicles passing at a specific point and time. Determining this can help reduce road congestion, support new designs for roads or intersections, improve safety, and more! Or, you can use to help plan your commute to avoid traffic!\n\nThe dataset provided contains the hourly traffic volume on an interstate highway in Minnesota, USA. It also includes weather features and holidays, which often impact traffic volume.\n\nTime to predict some traffic!\n\n### The data:\n\nThe dataset is collected and maintained by UCI Machine Learning Repository. The target variable is `traffic_volume`. The dataset contains the following and has already been normalized and saved into training and test sets:\n\n`train_scaled.csv`, `test_scaled.csv`\n| Column     | Type       | Description              |\n|------------|------------|--------------------------|\n|`temp`                   |Numeric            |Average temp in kelvin|\n|`rain_1h`                |Numeric            |Amount in mm of rain that occurred in the hour|\n|`snow_1h`                |Numeric            |Amount in mm of snow that occurred in the hour|\n|`clouds_all`             |Numeric            |Percentage of cloud cover|\n|`date_time`              |DateTime           |Hour of the data collected in local CST time|\n|`holiday_` (11 columns)  |Categorical        |US National holidays plus regional holiday, Minnesota State Fair|\n|`weather_main_` (11 columns)|Categorical     |Short textual description of the current weather|\n|`weather_description_` (35 columns)|Categorical|Longer textual description of the current weather|\n|`traffic_volume`         |Numeric            |Hourly I-94 ATR 301 reported westbound traffic volume|\n|`hour_of_day`|Numeric|The hour of the day|\n|`day_of_week`|Numeric|The day of the week (0=Monday, Sunday=6)|\n|`day_of_month`|Numeric|The day of the month|\n|`month`|Numeric|The number of the month|\n|`traffic_volume`         |Numeric            |Hourly I-94 ATR 301 reported westbound traffic volume|","metadata":{},"id":"8b752817-8333-446e-9790-73d85b0aa14f","cell_type":"markdown"},{"source":"# Import the relevant libraries\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"executionCancelledAt":null,"executionTime":4236,"lastExecutedAt":1732879448348,"lastExecutedByKernel":"331362a9-2ca1-4695-849c-84469c2dbe8c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the relevant libraries\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader","outputsMetadata":{"0":{"height":223,"type":"dataFrame"},"1":{"height":222,"type":"dataFrame"}}},"id":"d2e54daa-828a-420a-a204-f855de2ae375","cell_type":"code","execution_count":1,"outputs":[]},{"source":"# Read the traffic data from the CSV training and test files\ntrain_scaled_df = pd.read_csv('train_scaled.csv')\ntest_scaled_df = pd.read_csv('test_scaled.csv')\n\n\n# Separate features and target\nX_train = train_scaled_df.drop('traffic_volume', axis=1).values\ny_train = train_scaled_df['traffic_volume'].values\nX_test = test_scaled_df.drop('traffic_volume', axis=1).values\ny_test = test_scaled_df['traffic_volume'].values\n\n# Reshape data for LSTM (samples, time steps, features)\ndef create_sequences(X, y, time_steps=3):\n    X_seq, y_seq = [], []\n    for i in range(len(X) - time_steps):\n        X_seq.append(X[i:i+time_steps])\n        y_seq.append(y[i+time_steps])\n    return np.array(X_seq), np.array(y_seq)\n\n# Create sequences\nX_train_seq, y_train_seq = create_sequences(X_train, y_train)\nX_test_seq, y_test_seq = create_sequences(X_test, y_test)\n\n# Convert to PyTorch tensors\nX_train_tensor = torch.FloatTensor(X_train_seq)\ny_train_tensor = torch.FloatTensor(y_train_seq)\nX_test_tensor = torch.FloatTensor(X_test_seq)\ny_test_tensor = torch.FloatTensor(y_test_seq)","metadata":{"executionCancelledAt":null,"executionTime":270,"lastExecutedAt":1732879448620,"lastExecutedByKernel":"331362a9-2ca1-4695-849c-84469c2dbe8c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Read the traffic data from the CSV training and test files\ntrain_scaled_df = pd.read_csv('train_scaled.csv')\ntest_scaled_df = pd.read_csv('test_scaled.csv')\n\n\n# Separate features and target\nX_train = train_scaled_df.drop('traffic_volume', axis=1).values\ny_train = train_scaled_df['traffic_volume'].values\nX_test = test_scaled_df.drop('traffic_volume', axis=1).values\ny_test = test_scaled_df['traffic_volume'].values\n\n# Reshape data for LSTM (samples, time steps, features)\ndef create_sequences(X, y, time_steps=3):\n    X_seq, y_seq = [], []\n    for i in range(len(X) - time_steps):\n        X_seq.append(X[i:i+time_steps])\n        y_seq.append(y[i+time_steps])\n    return np.array(X_seq), np.array(y_seq)\n\n# Create sequences\nX_train_seq, y_train_seq = create_sequences(X_train, y_train)\nX_test_seq, y_test_seq = create_sequences(X_test, y_test)\n\n# Convert to PyTorch tensors\nX_train_tensor = torch.FloatTensor(X_train_seq)\ny_train_tensor = torch.FloatTensor(y_train_seq)\nX_test_tensor = torch.FloatTensor(X_test_seq)\ny_test_tensor = torch.FloatTensor(y_test_seq)","outputsMetadata":{"0":{"height":223,"type":"dataFrame"}}},"id":"58e3a3b9-9367-43e7-b13b-1f111447478e","cell_type":"code","execution_count":2,"outputs":[]},{"source":"class TrafficLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size):\n        super(TrafficLSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # LSTM layer\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n                            batch_first=True, dropout=0.2)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        # Initialize hidden state\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        \n        # LSTM forward pass\n        out, _ = self.lstm(x, (h0, c0))\n        \n        # Take the last time step\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Model Hyperparameters\ninput_size = X_train_seq.shape[2]\nhidden_size = 50\nnum_layers = 2\noutput_size = 1\n\n# Initialize the model\ntraffic_model = TrafficLSTM(input_size, hidden_size, num_layers, output_size)\n\n# Loss and Optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(traffic_model.parameters(), lr=0.001)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1732879448672,"lastExecutedByKernel":"331362a9-2ca1-4695-849c-84469c2dbe8c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"class TrafficLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size):\n        super(TrafficLSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # LSTM layer\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n                            batch_first=True, dropout=0.2)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        # Initialize hidden state\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        \n        # LSTM forward pass\n        out, _ = self.lstm(x, (h0, c0))\n        \n        # Take the last time step\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Model Hyperparameters\ninput_size = X_train_seq.shape[2]\nhidden_size = 50\nnum_layers = 2\noutput_size = 1\n\n# Initialize the model\ntraffic_model = TrafficLSTM(input_size, hidden_size, num_layers, output_size)\n\n# Loss and Optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(traffic_model.parameters(), lr=0.001)"},"id":"d29357d1-6cbb-4c86-ba49-ea31f6d8415e","cell_type":"code","execution_count":3,"outputs":[]},{"source":"num_epochs = 50\ntraining_losses = []\n\nfor epoch in range(num_epochs):\n    # Forward pass\n    outputs = traffic_model(X_train_tensor)\n    loss = criterion(outputs, y_train_tensor.unsqueeze(1))\n    \n    # Backward pass and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    training_losses.append(loss.item())\n    \n    # Print progress\n    if (epoch + 1) % 5 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Save final training loss\nfinal_training_loss = torch.tensor(training_losses[-1])","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":227,"type":"stream"}}},"cell_type":"code","id":"76d94238-1582-4ddc-aff4-7aef301a6c06","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch [5/50], Loss: 0.2456\nEpoch [10/50], Loss: 0.1843\nEpoch [15/50], Loss: 0.1276\nEpoch [20/50], Loss: 0.0841\nEpoch [25/50], Loss: 0.0810\nEpoch [30/50], Loss: 0.0854\nEpoch [35/50], Loss: 0.0761\nEpoch [40/50], Loss: 0.0762\nEpoch [45/50], Loss: 0.0769\nEpoch [50/50], Loss: 0.0753\n"}],"execution_count":4},{"source":"traffic_model.eval()\nwith torch.no_grad():\n    # Predict on test set\n    test_predictions = traffic_model(X_test_tensor)\n    \n    # Calculate Mean Squared Error\n    test_mse = F.mse_loss(test_predictions, y_test_tensor.unsqueeze(1))\n\n# Print results\nprint(f'Final Training Loss: {final_training_loss.item():.4f}')\nprint(f'Test MSE: {test_mse.item():.4f}')\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"84c270bb-6a2d-4058-a3b5-78d371dd2427","outputs":[{"output_type":"stream","name":"stdout","text":"Final Training Loss: 0.0753\nTest MSE: 0.0742\n"}],"execution_count":5}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}